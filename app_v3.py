import streamlit as st
import sys

# 1. æœ€å…ˆè®¾ç½®é¡µé¢é…ç½®ï¼ˆå¿…é¡»æ˜¯ç¬¬ä¸€ä¸ª Streamlit å‘½ä»¤ï¼‰
st.set_page_config(page_title="AI æ•°æ®åˆ†ç±»æ ‡æ³¨å·¥ä½œæµ", layout="wide")

# 2. å°è¯•åŠ è½½ä¾èµ–åº“ï¼Œå¦‚æœå‡ºé”™ç›´æ¥æ˜¾ç¤ºåœ¨ç•Œé¢ä¸Š
try:
    import pandas as pd
    import json
    import io
    import os
    import re
    import concurrent.futures
    from openai import OpenAI
except Exception as e:
    st.error(f"âŒ ä¾èµ–åº“åŠ è½½å¤±è´¥: {e}")
    st.stop()

# ==========================================
# è¾…åŠ©å‡½æ•°
# ==========================================

@st.cache_data(show_spinner=False)
def load_excel_sheets(file) -> list[str]:
    """è·å– Excel çš„æ‰€æœ‰ sheet åç§°"""
    try:
        xl = pd.ExcelFile(file)
        return xl.sheet_names
    except Exception as e:
        st.error(f"æ— æ³•è¯»å– Sheet: {e}")
        return []

@st.cache_data(show_spinner=False)
def load_excel(file, sheet_name) -> pd.DataFrame | None:
    try:
        return pd.read_excel(file, sheet_name=sheet_name)
    except Exception as e:
        st.error(f"æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
        return None

def call_llm(row, text_col, context_cols, system_prompt, api_key, base_url, model):
    try:
        client = OpenAI(api_key=api_key, base_url=base_url)
        context_text = "\n".join([f"{col}: {row.get(col, '')}" for col in context_cols])
        user_content = f"""
        ã€å¾…åˆ†æå†…å®¹ã€‘
        {text_col}: {row.get(text_col, '')}
        
        ã€è¾…åŠ©ä¿¡æ¯ã€‘
        {context_text}
        """
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_content}
            ],
            temperature=0.1
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Error: {str(e)}"

def parse_json_result(text: str) -> dict:
    try:
        # 1. å°è¯•ç›´æ¥è§£æ (å»é™¤å¯èƒ½å­˜åœ¨çš„ markdown ä»£ç å—æ ‡è®°)
        clean_text = text.replace("```json", "").replace("```", "").strip()
        return json.loads(clean_text)
    except:
        try:
            # 2. å¦‚æœç›´æ¥è§£æå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æ­£åˆ™æå–æœ€å¤–å±‚çš„ JSON å¯¹è±¡
            # åŒ¹é…ä»ç¬¬ä¸€ä¸ª { åˆ°æœ€åä¸€ä¸ª } çš„å†…å®¹
            match = re.search(r"\{[\s\S]*\}", text)
            if match:
                return json.loads(match.group(0))
        except:
            pass
        
        # 3. å½»åº•å¤±è´¥ï¼Œè¿”å›åŸå§‹æ–‡æœ¬ä»¥ä¾¿è°ƒè¯•
        return {"category": "Unknown", "reason": "JSON è§£æå¤±è´¥", "raw_output": text}

def stratified_sample(df: pd.DataFrame, label_col: str, frac: float = 0.1) -> pd.DataFrame:
    try:
        return df.groupby(label_col, group_keys=False).apply(
            lambda x: x.sample(frac=frac) if len(x) > 0 else x
        )
    except Exception as e:
        st.error(f"æŠ½æ ·å¤±è´¥ (å¯èƒ½æ˜¯åˆ†ç±»åˆ—æ•°æ®é—®é¢˜): {e}")
        return pd.DataFrame()

def get_ai_reasoning(row, text_col, context_cols, current_category, api_key, base_url, model):
    try:
        client = OpenAI(api_key=api_key, base_url=base_url)
        context_text = "\n".join([f"{col}: {row.get(col, '')}" for col in context_cols])
        user_content = f"""
        ã€å¾…åˆ†æå†…å®¹ã€‘
        {text_col}: {row.get(text_col, '')}
        
        ã€è¾…åŠ©ä¿¡æ¯ã€‘
        {context_text}
        
        ã€å½“å‰åˆ†ç±»ç»“æœã€‘
        {current_category}
        """
        prompt = f"è¯·è¯¦ç»†è§£é‡Šä¸ºä»€ä¹ˆè¿™ç¯‡å†…å®¹è¢«å½’ç±»ä¸ºâ€œ{current_category}â€ã€‚è¯·ç»“åˆå†…å®¹ç»†èŠ‚ç»™å‡ºå…·ä½“çš„åˆ†æç†ç”±ã€‚"
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æä¸“å®¶ã€‚"},
                {"role": "user", "content": user_content + "\n\n" + prompt}
            ],
            temperature=0.3
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Error: {str(e)}"

def analyze_misclassification(corrections, processed_data, df, text_col, system_prompt, api_key, base_url, model):
    examples = []
    for idx, correct_label in corrections.items():
        ai_res = processed_data.get(idx, {})
        ai_label = ai_res.get("category", "Unknown")
        content = str(df.loc[idx, text_col])[:200]
        examples.append(f"ã€æ¡ˆä¾‹ã€‘\\nå†…å®¹: {content}...\\nAIåŸåˆ¤: {ai_label}\\näººå·¥ä¿®æ­£: {correct_label}\\n")
    
    examples_text = "\\n".join(examples)
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ª Prompt ä¼˜åŒ–ä¸“å®¶ã€‚ä»¥ä¸‹æ˜¯ AI åˆ†ç±»é”™è¯¯ä¸äººå·¥ä¿®æ­£çš„å¯¹æ¯”æ¡ˆä¾‹ï¼š
    {examples_text}
    
    ã€å½“å‰ System Promptã€‘
    {system_prompt}
    
    è¯·æ‰§è¡Œä»¥ä¸‹ä»»åŠ¡ï¼š
    1. åˆ†æè¯¯åˆ¤åŸå› ï¼Œå¹¶è¾“å‡ºé’ˆå¯¹ System Prompt çš„å…·ä½“ä¿®æ”¹å»ºè®®ï¼ˆä»¥â€œå»ºè®®åœ¨ Prompt ä¸­å¢åŠ è§„åˆ™ï¼š......â€çš„æ ¼å¼ï¼‰ã€‚
    2. æ ¹æ®ä½ çš„å»ºè®®ï¼Œä¿®æ”¹å¹¶ç”Ÿæˆä¸€ä¸ªæ–°çš„ System Promptã€‚
    
    è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š
    ã€åˆ†æä¸å»ºè®®ã€‘
    ...ä½ çš„åˆ†æ...
    
    ã€ä¼˜åŒ–åçš„ System Promptã€‘
    ...æ–°çš„ Prompt å†…å®¹...
    """
    try:
        client = OpenAI(api_key=api_key, base_url=base_url)
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Error: {str(e)}"

def render_prompt_lab(df):
    st.subheader("åŒºåŸŸ A: æ§åˆ¶å°")
    c1, c2 = st.columns([1, 1])
    
    with c1:
        st.markdown("##### ğŸ“ System Prompt ç¼–è¾‘")
        
        # 1. Prompt ä¼˜åŒ–å¯¹è¯åŒº (ç§»è‡³ä¸Šæ–¹)
        with st.expander("ğŸ’¬ AI ä¼˜åŒ–åŠ©æ‰‹ (ç‚¹å‡»å±•å¼€)", expanded=False):
            if "chat_history" not in st.session_state:
                st.session_state.chat_history = []

            chat_container = st.container(height=200)
            for msg in st.session_state.chat_history:
                chat_container.chat_message(msg["role"]).write(msg["content"])

            if prompt_input := st.chat_input("è¾“å…¥ä¿®æ”¹éœ€æ±‚ï¼ˆä¾‹å¦‚ï¼šå¢åŠ 'è´­ä¹°æ„æ„¿'å­—æ®µï¼‰..."):
                st.session_state.chat_history.append({"role": "user", "content": prompt_input})
                chat_container.chat_message("user").write(prompt_input)
                
                try:
                    client = OpenAI(api_key=st.session_state.api_key, base_url=st.session_state.base_url)
                    optimize_prompt = f"""
                    ä½ æ˜¯ä¸€ä¸ª Prompt ä¼˜åŒ–ä¸“å®¶ã€‚
                    ã€å½“å‰ Promptã€‘
                    {st.session_state.system_prompt}
                    ã€ç”¨æˆ·éœ€æ±‚ã€‘
                    {prompt_input}
                    è¯·æ ¹æ®ç”¨æˆ·éœ€æ±‚ä¿®æ”¹å½“å‰ Promptã€‚åªè¿”å›ä¿®æ”¹åçš„ Prompt å†…å®¹ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šã€‚
                    """
                    response = client.chat.completions.create(
                        model=st.session_state.model_name,
                        messages=[{"role": "user", "content": optimize_prompt}],
                        temperature=0.7
                    )
                    ai_reply = response.choices[0].message.content
                    st.session_state.chat_history.append({"role": "assistant", "content": ai_reply})
                    chat_container.chat_message("assistant").write(ai_reply)
                    st.info("ğŸ’¡ AI å·²ç”Ÿæˆæ–° Promptï¼Œè¯·æ‰‹åŠ¨å¤åˆ¶ä¸Šæ–¹å›å¤å†…å®¹ã€‚")
                except Exception as e:
                    st.error(f"AI è°ƒç”¨å¤±è´¥: {e}")

        # 2. System Prompt ç¼–è¾‘æ¡†
        if "system_prompt" not in st.session_state:
            st.session_state.system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åˆ†ç±»åŠ©æ‰‹ã€‚è¯·åˆ†æå†…å®¹ï¼Œå¹¶ä¸¥æ ¼è¾“å‡ºä»¥ä¸‹ JSON æ ¼å¼ï¼š\n{\n    "category": "äº‹ä»¶åˆ†ç±»",\n    "sentiment": "æƒ…æ„Ÿå€¾å‘",\n    "reason": "åˆ¤æ–­ç†ç”±"\n}"""
        st.session_state.system_prompt = st.text_area("System Prompt", st.session_state.system_prompt, height=400, label_visibility="collapsed")

    with c2:
        st.markdown("##### âš™ï¸ æµ‹è¯•ä¸ä¼˜åŒ–")
        # æµ‹è¯•æ§åˆ¶åŒº (ç§»è‡³ä¸‹æ–¹ï¼Œå¯¹åº”å³ä¾§å¸ƒå±€)
        # ä¸ºäº†å¹³è¡¡å¸ƒå±€ï¼Œæˆ‘ä»¬åœ¨å³ä¾§ä¸Šæ–¹æ”¾ä¸€äº›è¯´æ˜æˆ–ç•™ç™½ï¼Œæˆ–è€…ç›´æ¥æ”¾æµ‹è¯•æ§åˆ¶
        
        st.info("ğŸ‘‰ åœ¨å·¦ä¾§ç¼–è¾‘ Promptï¼Œæˆ–ä½¿ç”¨ä¸Šæ–¹çš„ AI åŠ©æ‰‹è¿›è¡Œä¼˜åŒ–ã€‚å®Œæˆååœ¨ä¸‹æ–¹è¿›è¡Œæµ‹è¯•ã€‚")
        
        st.divider()
        
        t1, t2 = st.columns([1, 1])
        with t1:
            test_n = st.number_input("æŠ½æ ·æ•°é‡", 1, 500, 50)
        with t2:
            st.write("")
            st.write("")
            start_test = st.button("â–¶ï¸ å¼€å§‹æµ‹è¯•", type="primary", use_container_width=True)

    if start_test:
        sample_df = df.sample(n=min(test_n, len(df)))
        st.session_state.test_indices = sample_df.index.tolist()
        st.session_state.test_results = {}
        
        with st.status("æ­£åœ¨è¿›è¡Œ AI æµ‹è¯•...", expanded=True) as status:
            with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:
                futures = {executor.submit(call_llm, df.loc[i], st.session_state.text_col, st.session_state.context_cols, st.session_state.system_prompt, st.session_state.api_key, st.session_state.base_url, st.session_state.model_name): i for i in sample_df.index}
                for f in concurrent.futures.as_completed(futures):
                    i = futures[f]
                    st.session_state.test_results[i] = parse_json_result(f.result())
            status.update(label="æµ‹è¯•å®Œæˆ", state="complete")

    if "test_results" in st.session_state and st.session_state.test_results:
        st.subheader("åŒºåŸŸ B: ç»“æœé€è§†")
        results = st.session_state.test_results
        
        # 1. è‡ªåŠ¨æ¢æµ‹æ‰€æœ‰çš„ key
        all_keys = set()
        for r in results.values():
            if isinstance(r, dict):
                all_keys.update(r.keys())
        
        # æ’é™¤ reason, raw_output ç­‰éæ ‡ç­¾ key
        candidate_keys = [k for k in all_keys if k not in ["reason", "raw_output", "error"]]
        
        if not candidate_keys:
            st.warning("æœªæ£€æµ‹åˆ°æœ‰æ•ˆçš„ JSON æ ‡ç­¾å­—æ®µï¼Œè¯·æ£€æŸ¥ Prompt è¾“å‡ºæ ¼å¼ã€‚")
        else:
            # è®©ç”¨æˆ·é€‰æ‹©å½“å‰è¦åˆ†æçš„ç»´åº¦
            if "target_label_key" not in st.session_state:
                st.session_state.target_label_key = candidate_keys[0] if candidate_keys else ""
            
            # å¦‚æœä¹‹å‰çš„ key ä¸åœ¨äº†ï¼Œé‡ç½®
            if st.session_state.target_label_key not in candidate_keys and candidate_keys:
                st.session_state.target_label_key = candidate_keys[0]
                
            c_view1, c_view2 = st.columns([1, 3])
            with c_view1:
                st.session_state.target_label_key = st.selectbox("ğŸ“Š é€‰æ‹©åˆ†æç»´åº¦", candidate_keys, index=candidate_keys.index(st.session_state.target_label_key))
            
            target_key = st.session_state.target_label_key
            
            # æå–å½“å‰ç»´åº¦çš„å€¼
            current_values = [r.get(target_key, "Unknown") for r in results.values() if isinstance(r, dict)]
            
            # ç»Ÿè®¡å±•ç¤º
            counts = pd.Series(current_values).value_counts()
            st.markdown(f"**ğŸ“ˆ '{target_key}' åˆ†å¸ƒæ¦‚è§ˆ**")
            
            # è½¬ç½®å±•ç¤º
            count_df = counts.to_frame(name="æ•°é‡").T
            st.dataframe(count_df, use_container_width=True)
        
            unique_cats = sorted(list(set(current_values)))
            if hasattr(st, "pills"):
                selected_cat = st.pills(f"é€‰æ‹© '{target_key}' æŸ¥çœ‹è¯¦æƒ…", unique_cats, selection_mode="single")
            else:
                selected_cat = st.radio(f"é€‰æ‹© '{target_key}' æŸ¥çœ‹è¯¦æƒ…", unique_cats, horizontal=True)
                
            if selected_cat:
                # ç­›é€‰å‡ºå½“å‰ç»´åº¦ç¬¦åˆé€‰å®šå€¼çš„ index
                cat_indices = [i for i, r in results.items() if r.get(target_key, "Unknown") == selected_cat]
                display_indices = cat_indices[:5] 
                
                st.write("ğŸ‘€ **æ˜¾ç¤ºè®¾ç½®**")
                all_cols = df.columns.tolist()
                default_cols = [st.session_state.text_col] + [c for c in st.session_state.context_cols if c in all_cols]
                show_cols = st.multiselect("é€‰æ‹©åœ¨è¯¦æƒ…ä¸­å±•ç¤ºçš„åŸå§‹åˆ—", all_cols, default=default_cols)
                
                for idx in display_indices:
                    with st.expander(f"ğŸ“„ {str(df.loc[idx, st.session_state.text_col])[:50]}...", expanded=True):
                        col_content, col_reason = st.columns([2, 1])
                        with col_content:
                            if show_cols:
                                for col in show_cols:
                                    st.write(f"**{col}:**")
                                    st.caption(df.loc[idx, col])
                            else:
                                st.write("**å†…å®¹:**")
                                st.write(df.loc[idx, st.session_state.text_col])
                                
                            st.write(f"**AI åˆ¤å®šç†ç”±:** {results[idx].get('reason', 'N/A')}")
                            
                            # æ˜¾ç¤ºæ‰€æœ‰æå–åˆ°çš„æ ‡ç­¾
                            st.write("**AI æå–çš„æ‰€æœ‰æ ‡ç­¾:**")
                            st.json({k: v for k, v in results[idx].items() if k not in ["reason", "raw_output"]})
                            
                            if "raw_output" in results[idx]:
                                st.warning("âš ï¸ æ— æ³•è§£æ AI è¿”å›çš„ JSON")
                                st.code(results[idx]["raw_output"], language="json")

                            if st.button("ğŸ§  æ·±åº¦ AI å½’å› ", key=f"btn_reason_{idx}"):
                                reason = get_ai_reasoning(df.loc[idx], st.session_state.text_col, st.session_state.context_cols, f"{target_key}={selected_cat}", st.session_state.api_key, st.session_state.base_url, st.session_state.model_name)
                                st.info(reason)
                        
                        with col_reason:
                            st.write(f"**äººå·¥ä¿®æ­£ ({target_key}):**")
                            
                            # è·å–å½“å‰é’ˆå¯¹è¯¥ idx è¯¥ key çš„ä¿®æ­£å€¼
                            # manual_corrections ç»“æ„æ”¹ä¸º: {idx: {key1: val1, key2: val2}}
                            current_corrections = st.session_state.manual_corrections.get(idx, {})
                            current_fix = current_corrections.get(target_key, selected_cat)
                            
                            options = unique_cats + ["è‡ªå®šä¹‰..."]
                            
                            if current_fix in unique_cats:
                                idx_sel = unique_cats.index(current_fix)
                            else:
                                idx_sel = len(unique_cats) # "è‡ªå®šä¹‰..."

                            new_fix_select = st.selectbox("ä¿®æ­£åˆ†ç±»", options, index=idx_sel, key=f"fix_sel_{idx}_{target_key}")
                            
                            final_fix = new_fix_select
                            if new_fix_select == "è‡ªå®šä¹‰...":
                                default_custom = current_fix if current_fix not in unique_cats else ""
                                custom_val = st.text_input("è¾“å…¥è‡ªå®šä¹‰å€¼", value=default_custom, key=f"fix_custom_{idx}_{target_key}")
                                if custom_val:
                                    final_fix = custom_val
                            
                            # ä¿å­˜ä¿®æ­£é€»è¾‘
                            if final_fix != selected_cat:
                                if idx not in st.session_state.manual_corrections:
                                    st.session_state.manual_corrections[idx] = {}
                                st.session_state.manual_corrections[idx][target_key] = final_fix

        st.subheader("åŒºåŸŸ C: ä¼˜åŒ–å»ºè®®")
        if st.button("æ ¹æ®æˆ‘çš„ä¿®æ­£ç”Ÿæˆ Prompt ä¿®æ”¹å»ºè®®"):
            if not st.session_state.manual_corrections:
                st.warning("è¯·å…ˆåœ¨ä¸Šæ–¹è¿›è¡Œä¸€äº›äººå·¥ä¿®æ­£ã€‚")
            else:
                # æ„é€ ä¼ é€’ç»™ AI çš„ä¿®æ­£æ•°æ®ï¼ŒåªåŒ…å«å½“å‰å…³æ³¨çš„ target_key ç›¸å…³çš„ä¿®æ­£
                target_key = st.session_state.get("target_label_key", "category")
                relevant_corrections = {}
                for idx, corrections in st.session_state.manual_corrections.items():
                    if target_key in corrections:
                        relevant_corrections[idx] = corrections[target_key]
                
                if not relevant_corrections:
                     st.warning(f"è¯·å…ˆé’ˆå¯¹å½“å‰åˆ†æç»´åº¦ '{target_key}' è¿›è¡Œä¸€äº›ä¿®æ­£ã€‚")
                else:
                    with st.spinner(f"AI æ­£åœ¨åˆ†æ '{target_key}' çš„è¯¯åˆ¤åŸå› ..."):
                        # ä¸´æ—¶æ„é€ ä¸€ä¸ªåªåŒ…å« target_key çš„ processed_data è§†å›¾ç»™åˆ†æå‡½æ•°
                        temp_processed_data = {}
                        for idx, res in results.items():
                            temp_processed_data[idx] = {"category": res.get(target_key, "Unknown")} # æ¬ºéª—å‡½æ•°åä¸º category

                        suggestion = analyze_misclassification(
                            relevant_corrections, 
                            temp_processed_data, 
                            df, 
                            st.session_state.text_col, 
                            st.session_state.system_prompt, 
                            st.session_state.api_key, 
                            st.session_state.base_url, 
                            st.session_state.model_name
                        )
                        
                        parts = suggestion.split("ã€ä¼˜åŒ–åçš„ System Promptã€‘")
                        if len(parts) == 2:
                            analysis_text = parts[0].replace("ã€åˆ†æä¸å»ºè®®ã€‘", "").strip()
                            new_prompt_text = parts[1].strip()
                            
                            st.markdown("#### ğŸ’¡ åˆ†æä¸å»ºè®®")
                            st.markdown(analysis_text)
                            
                            st.markdown("#### âœ¨ ä¼˜åŒ–åçš„ System Prompt")
                            st.code(new_prompt_text, language="text")
                            st.info("è¯·å¤åˆ¶ä¸Šé¢çš„ Promptï¼Œå¹¶æ›¿æ¢å·¦ä¾§çš„ System Prompt ç¼–è¾‘æ¡†å†…å®¹ã€‚")
                        else:
                            st.markdown(suggestion)

def render_batch_run(df):
    st.header("3. å…¨é‡è¿è¡Œ")
    
    st.markdown("#### ğŸ› ï¸ ç¡®è®¤ç”Ÿäº§ Prompt")
    st.info("è¯·åœ¨æ­¤ç¡®è®¤æœ€ç»ˆç”¨äºå…¨é‡è·‘æ•°çš„ System Promptã€‚")
    st.session_state.system_prompt = st.text_area(
        "System Prompt ç¡®è®¤", 
        value=st.session_state.system_prompt, 
        height=300,
        key="batch_prompt_confirm"
    )
    
    if st.button("ğŸš€ è¿è¡Œå‰©ä½™æ‰€æœ‰æ•°æ®"):
        all_indices = df.index.tolist()
        remaining_indices = [i for i in all_indices if i not in st.session_state.processed_data]
        if not remaining_indices:
            st.warning("æ‰€æœ‰æ•°æ®å·²å¤„ç†ã€‚")
        else:
            st.info(f"æ­£åœ¨å¹¶å‘å¤„ç† {len(remaining_indices)} æ¡æ•°æ®...")
            progress_bar = st.progress(0.0)
            status_text_run = st.empty()
            completed = 0
            total = len(remaining_indices)
            with concurrent.futures.ThreadPoolExecutor(max_workers=50) as executor:
                future_to_idx = {
                    executor.submit(call_llm, df.loc[idx], st.session_state.text_col, st.session_state.context_cols, st.session_state.system_prompt, st.session_state.api_key, st.session_state.base_url, st.session_state.model_name): idx 
                    for idx in remaining_indices
                }
                for future in concurrent.futures.as_completed(future_to_idx):
                    idx = future_to_idx[future]
                    try:
                        res = future.result()
                        parsed = parse_json_result(res)
                        st.session_state.processed_data[idx] = parsed
                    except Exception as e:
                        st.session_state.processed_data[idx] = {"error": str(e)}
                    completed += 1
                    progress_bar.progress(completed / total)
                    status_text_run.text(f"è¿›åº¦ï¼š{completed}/{total}")
            st.success("å…¨é‡è¿è¡Œå®Œæˆï¼")

    if st.session_state.processed_data:
        st.header("4. ç»“æœè´¨æ£€ä¸éªŒæ”¶")
        
        # Merge data
        merged_rows = []
        for idx in df.index:
            base_row = df.loc[idx].to_dict()
            ai_res = st.session_state.processed_data.get(idx, {})
            for k, v in ai_res.items():
                base_row[f"AI_{k}"] = v
            merged_rows.append(base_row)
        final_df = pd.DataFrame(merged_rows)
        
        # QA State Initialization
        if "qa_indices" not in st.session_state:
            st.session_state.qa_indices = []
        if "qa_corrections" not in st.session_state:
            st.session_state.qa_corrections = {}

        # 4.1 Sampling Control
        st.markdown("##### ğŸ” æŠ½æ ·è´¨æ£€")
        c_qa_1, c_qa_2, c_qa_3 = st.columns([1, 1, 2])
        with c_qa_1:
            # Detect AI category columns (excluding reason/raw_output)
            ai_cols = [c for c in final_df.columns if c.startswith("AI_") and not any(x in c.lower() for x in ["reason", "raw_output", "error"])]
            
            if not ai_cols:
                st.warning("æœªæ‰¾åˆ°æœ‰æ•ˆçš„ AI æ ‡ç­¾åˆ—ã€‚")
                qa_col = None
            else:
                qa_col = st.selectbox("é€‰æ‹©è´¨æ£€ä¾æ®åˆ—", ai_cols, key="qa_col_select")
        
        with c_qa_2:
            sample_size = st.number_input("æŠ½æ ·æ•°é‡", min_value=10, max_value=1000, value=50)
        
        with c_qa_3:
            st.write("")
            st.write("")
            if st.button("ğŸ² ç”Ÿæˆæ–°çš„è´¨æ£€æ ·æœ¬", type="primary"):
                try:
                    if len(final_df) > sample_size:
                         qa_sample = final_df.sample(n=sample_size)
                    else:
                        qa_sample = final_df
                    
                    st.session_state.qa_indices = qa_sample.index.tolist()
                    st.session_state.qa_corrections = {} # Reset corrections
                    st.success(f"å·²æŠ½å– {len(qa_sample)} æ¡æ•°æ®è¿›è¡Œè´¨æ£€")
                    st.rerun()
                except Exception as e:
                    st.error(f"æŠ½æ ·å¤±è´¥: {e}")

        # 4.2 QA Interface
        if st.session_state.qa_indices and qa_col:
            st.divider()
            qa_df = final_df.loc[st.session_state.qa_indices]
            
            # Error Rate Calculation (based on current qa_col)
            # count how many indices have a correction for the current qa_col
            error_count = 0
            for idx in st.session_state.qa_indices:
                if idx in st.session_state.qa_corrections:
                    if qa_col in st.session_state.qa_corrections[idx]:
                        error_count += 1
            
            total_checked = len(qa_df)
            error_rate = (error_count / total_checked) * 100 if total_checked > 0 else 0
            
            # Metrics Display
            m1, m2, m3 = st.columns(3)
            m1.metric("æŠ½æ ·æ€»é‡", total_checked)
            m2.metric(f"'{qa_col}' é”™è¯¯æ•°", error_count, delta_color="inverse")
            m3.metric("å½“å‰é”™è¯¯ç‡", f"{error_rate:.1f}%", delta_color="inverse")
            
            # Category Filter
            categories = qa_df[qa_col].astype(str).tolist()
            unique_cats = sorted(list(set(categories)))
            
            if hasattr(st, "pills"):
                selected_cat_qa = st.pills(f"é€‰æ‹© '{qa_col}' æŸ¥çœ‹æ ·æœ¬", unique_cats, selection_mode="single", key="qa_pills")
            else:
                selected_cat_qa = st.radio(f"é€‰æ‹© '{qa_col}' æŸ¥çœ‹æ ·æœ¬", unique_cats, horizontal=True, key="qa_radio")
            
            if selected_cat_qa:
                # Filter indices for this category
                cat_indices = qa_df[qa_df[qa_col] == selected_cat_qa].index.tolist()
                
                if not cat_indices:
                    st.info(f"åˆ†ç±» '{selected_cat_qa}' ä¸‹æ²¡æœ‰æ ·æœ¬æ•°æ®ã€‚")
                else:
                    for idx in cat_indices:
                        # Determine current status
                        is_error = False
                        corrected_label = selected_cat_qa
                        
                        if idx in st.session_state.qa_corrections:
                             if qa_col in st.session_state.qa_corrections[idx]:
                                 is_error = True
                                 corrected_label = st.session_state.qa_corrections[idx][qa_col]
                        
                        # Card View
                        with st.expander(f"{'âŒ' if is_error else 'âœ…'} {str(qa_df.loc[idx, st.session_state.text_col])[:50]}...", expanded=True):
                            qc1, qc2 = st.columns([3, 1])
                            with qc1:
                                st.markdown(f"**å†…å®¹:** {qa_df.loc[idx, st.session_state.text_col]}")
                                st.caption(f"AI åŸåˆ¤ ({qa_col}): {selected_cat_qa}")
                                if f"AI_reason" in qa_df.columns:
                                     st.caption(f"ç†ç”±: {qa_df.loc[idx, 'AI_reason']}")
                                
                                # Show other AI tags
                                other_tags = {c: qa_df.loc[idx, c] for c in ai_cols if c != qa_col}
                                if other_tags:
                                    st.caption(f"å…¶ä»–æ ‡ç­¾: {other_tags}")

                            with qc2:
                                # Manual Correction UI
                                options = unique_cats + ["è‡ªå®šä¹‰..."]
                                # Current selection index
                                if corrected_label in unique_cats:
                                    sel_idx = unique_cats.index(corrected_label)
                                else:
                                    sel_idx = len(unique_cats) # Custom
                                    
                                new_correction = st.selectbox("æ ¡å‡†åˆ†ç±»", options, index=sel_idx, key=f"qa_fix_{idx}_{qa_col}")
                                
                                final_correction = new_correction
                                if new_correction == "è‡ªå®šä¹‰...":
                                    default_custom = corrected_label if corrected_label not in unique_cats else ""
                                    final_correction = st.text_input("è¾“å…¥åˆ†ç±»", value=default_custom, key=f"qa_custom_{idx}_{qa_col}")
                                
                                # Logic to update state and rerun if changed
                                if final_correction != corrected_label:
                                    if idx not in st.session_state.qa_corrections:
                                        st.session_state.qa_corrections[idx] = {}
                                    
                                    if final_correction != selected_cat_qa:
                                        st.session_state.qa_corrections[idx][qa_col] = final_correction
                                    else:
                                        # Reverted to original
                                        if qa_col in st.session_state.qa_corrections[idx]:
                                            del st.session_state.qa_corrections[idx][qa_col]
                                            # Clean up if empty
                                            if not st.session_state.qa_corrections[idx]:
                                                del st.session_state.qa_corrections[idx]
                                    st.rerun()

        # 4.3 QA Prompt Optimization
        st.divider()
        st.subheader("ğŸ¤– AI è´¨æ£€æ€»ç»“ä¸ Prompt è¿­ä»£")
        
        st.info("åŸºäºä¸Šè¿°è´¨æ£€è¿‡ç¨‹ä¸­çš„äººå·¥ä¿®æ­£ï¼Œè®© AI åˆ†æè¯¯åˆ¤åŸå› å¹¶ç”Ÿæˆä¸‹ä¸€æ¬¡è¿­ä»£çš„ System Prompt å»ºè®®ã€‚")
        
        if st.button("ç”Ÿæˆè´¨æ£€æŠ¥å‘Šä¸ä¼˜åŒ–å»ºè®®", type="primary"):
            if not st.session_state.qa_corrections:
                st.warning("æ‚¨å°šæœªè¿›è¡Œä»»ä½•äººå·¥ä¿®æ­£ï¼Œæ— æ³•åˆ†æè¯¯åˆ¤åŸå› ã€‚")
            else:
                with st.spinner("AI æ­£åœ¨åˆ†æå…¨é‡è´¨æ£€ç»“æœ..."):
                    # Flatten corrections for the current column for analysis
                    flat_corrections = {}
                    current_qa_col = qa_col # Use the currently selected column for analysis
                    
                    for idx, cors in st.session_state.qa_corrections.items():
                        if current_qa_col in cors:
                            flat_corrections[idx] = cors[current_qa_col]
                    
                    if not flat_corrections:
                        st.warning(f"è¯·å…ˆé’ˆå¯¹å½“å‰é€‰æ‹©çš„åˆ— '{current_qa_col}' è¿›è¡Œä¸€äº›ä¿®æ­£ã€‚")
                    else:
                        suggestion = analyze_misclassification(
                            flat_corrections, 
                            {i: {"category": qa_df.loc[i, current_qa_col]} for i in qa_df.index}, 
                            df, 
                            st.session_state.text_col, 
                            st.session_state.system_prompt, 
                            st.session_state.api_key, 
                            st.session_state.base_url, 
                            st.session_state.model_name
                        )
                        
                        # Display results (same format as Tab 2)
                        parts = suggestion.split("ã€ä¼˜åŒ–åçš„ System Promptã€‘")
                        if len(parts) == 2:
                            analysis_text = parts[0].replace("ã€åˆ†æä¸å»ºè®®ã€‘", "").strip()
                            new_prompt_text = parts[1].strip()
                            
                            st.markdown("#### ğŸ’¡ è´¨æ£€åˆ†ææŠ¥å‘Š")
                            st.markdown(analysis_text)
                            
                            st.markdown("#### âœ¨ ä¸‹ä¸€ç‰ˆ System Prompt å»ºè®®")
                            st.code(new_prompt_text, language="text")
                            st.success("æ‚¨å¯ä»¥å¤åˆ¶æ­¤ Prompt ç”¨äºä¸‹ä¸€æ‰¹æ•°æ®çš„ç”Ÿäº§ï¼Œæˆ–åœ¨ Prompt å®éªŒå®¤ä¸­è¿›ä¸€æ­¥å¾®è°ƒã€‚")
                        else:
                            st.markdown(suggestion)

        st.divider()
        st.subheader("ğŸ“¥ å¯¼å‡ºæœ€ç»ˆç»“æœ")
        
        # Prepare Export Data
        export_df = final_df.copy()
        
        # Apply corrections
        # qa_corrections format: {idx: {col: val, col2: val2}}
        for idx, col_map in st.session_state.qa_corrections.items():
            for col_name, correct_val in col_map.items():
                # Update the original AI column directly or create a new one?
                # Let's create a Final_ column
                final_col_name = f"Final_{col_name.replace('AI_', '')}"
                export_df.loc[idx, final_col_name] = correct_val
                
                # Also mark as corrected
                export_df.loc[idx, f"Is_Corrected_{col_name}"] = True
                export_df.loc[idx, f"Corrected_From_{col_name}"] = export_df.loc[idx, col_name]

        # Fill Final columns for uncorrected rows
        for col in export_df.columns:
            if col.startswith("AI_") and "reason" not in col and "raw" not in col:
                final_col_name = f"Final_{col.replace('AI_', '')}"
                if final_col_name not in export_df.columns:
                    export_df[final_col_name] = export_df[col]
                else:
                    export_df[final_col_name] = export_df[final_col_name].fillna(export_df[col])

        col_a, col_b = st.columns(2)
        with col_a:
            buffer = io.BytesIO()
            with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
                export_df.to_excel(writer, index=False)
            st.download_button("ğŸ“¥ ä¸‹è½½å…¨é‡ç»“æœ (å«ä¿®æ­£)", buffer.getvalue(), "æ‰“æ ‡ç»“æœ_æœ€ç»ˆ.xlsx")
            
        with col_b:
             st.info("å¯¼å‡ºè¯´æ˜ï¼šæ–‡ä»¶ä¸­å°†åŒ…å« 'Final_*' åˆ—ï¼Œä¸ºæœ€ç»ˆé‡‡ç”¨çš„åˆ†ç±»ç»“æœï¼ˆåŒ…å«äººå·¥ä¿®æ­£ï¼‰ã€‚")

# ==========================================
# ä¸»ç¨‹åºé€»è¾‘
# ==========================================

def main_app():
    st.title("ğŸ¤– AI æ•°æ®åˆ†ç±»æ ‡æ³¨å·¥ä½œæµï¼ˆV3 ç¨³å®šç‰ˆï¼‰")
    
    for key, default in [("df", None), ("processed_data", {}), ("manual_corrections", {}), ("test_results", {}), ("error_flags", {}), ("qa_indices", []), ("qa_corrections", {})]:
        if key not in st.session_state: st.session_state[key] = default

    # å¢åŠ è‡ªå®šä¹‰ CSS æ”¾å¤§ Tab å­—ä½“
    st.markdown("""
    <style>
        div[data-baseweb="tab-list"] p {
            font-size: 1.2rem;
            font-weight: 600;
        }
    </style>
    """, unsafe_allow_html=True)

    tab1, tab2, tab3 = st.tabs(["1ï¸âƒ£ ç¬¬ä¸€æ­¥ï¼šæ•°æ®ä¸Šä¼ ", "2ï¸âƒ£ ç¬¬äºŒæ­¥ï¼šPrompt å®éªŒå®¤", "3ï¸âƒ£ ç¬¬ä¸‰æ­¥ï¼šæ‰¹é‡ç”Ÿäº§"])
    
    with tab1:
        st.header("1. é…ç½®ä¸ä¸Šä¼ ")
        with st.expander("ğŸ“‚ æ–‡ä»¶ä¸ API è®¾ç½®", expanded=True):
            col1, col2 = st.columns(2)
            with col1:
                uploaded_file = st.file_uploader("ä¸Šä¼  Excel æ–‡ä»¶", type=["xlsx", "xls"])
                if uploaded_file:
                    sheet_names = load_excel_sheets(uploaded_file)
                    if sheet_names:
                        selected_sheet = st.selectbox("é€‰æ‹© Sheet", sheet_names)
                        if st.button("ç¡®è®¤åŠ è½½æ•°æ®"):
                             with st.spinner("æ­£åœ¨è¯»å– Excel..."):
                                df_loaded = load_excel(uploaded_file, selected_sheet)
                                if df_loaded is not None:
                                    st.session_state.df = df_loaded.reset_index(drop=True)
                                    st.success("æ•°æ®å·²å°±ç»ªï¼Œè¯·åˆ‡æ¢åˆ°ã€Promptå®éªŒå®¤ã€‘è¿›è¡Œè°ƒè¯•")
                if st.session_state.df is not None:
                    st.info(f"å½“å‰å·²åŠ è½½: {len(st.session_state.df)} æ¡")
            with col2:
                if "api_key" not in st.session_state: st.session_state.api_key = "sk-xxxx"
                st.session_state.api_key = st.text_input("API Key", value=st.session_state.api_key, type="password")
                if "base_url" not in st.session_state: st.session_state.base_url = "https://ark.cn-beijing.volces.com/api/v3"
                st.session_state.base_url = st.text_input("Base URL", value=st.session_state.base_url)
                if "model_name" not in st.session_state: st.session_state.model_name = "ep-20250530201032-d9f2d"
                st.session_state.model_name = st.text_input("Model Name", value=st.session_state.model_name)

        if st.session_state.df is not None:
            c1, c2 = st.columns(2)
            st.session_state.text_col = c1.selectbox("é€‰æ‹©ä¸»è¦å†…å®¹åˆ—", st.session_state.df.columns)
            st.session_state.context_cols = c2.multiselect("é€‰æ‹©è¾…åŠ©ä¿¡æ¯åˆ—", [c for c in st.session_state.df.columns if c != st.session_state.text_col])
    
    with tab2:
        if st.session_state.df is None:
            st.warning("è¯·å…ˆåœ¨ Tab 1 ä¸Šä¼ æ•°æ®")
        else:
            render_prompt_lab(st.session_state.df)
    
    with tab3:
        if st.session_state.df is None:
            st.warning("è¯·å…ˆä¸Šä¼ æ•°æ®")
        else:
            render_batch_run(st.session_state.df)

def main_app_old():
    # æ¸…é™¤å¯åŠ¨æç¤º
    status_text.empty()
    st.title("ğŸ¤– AI æ•°æ®åˆ†ç±»æ ‡æ³¨å·¥ä½œæµï¼ˆV3 ç¨³å®šç‰ˆï¼‰")

    if "df" not in st.session_state:
        st.session_state.df = None
    if "sample_indices" not in st.session_state:
        st.session_state.sample_indices = []
    if "processed_data" not in st.session_state:
        st.session_state.processed_data = {}
    if "error_flags" not in st.session_state:
        st.session_state.error_flags = {}

    st.header("1. é…ç½®ä¸ä¸Šä¼ ")

    with st.expander("ğŸ“‚ æ–‡ä»¶ä¸ API è®¾ç½®", expanded=True):
        col1, col2 = st.columns(2)

        with col1:
            uploaded_file = st.file_uploader("ä¸Šä¼  Excel æ–‡ä»¶", type=["xlsx", "xls"])
            if uploaded_file:
                # 1. å…ˆè¯»å– sheet åˆ—è¡¨
                sheet_names = load_excel_sheets(uploaded_file)
                if sheet_names:
                    selected_sheet = st.selectbox("é€‰æ‹© Sheet", sheet_names)
                    
                    # 2. åªæœ‰å½“ç”¨æˆ·é€‰æ‹©äº† sheet ä¸”å°šæœªåŠ è½½æ•°æ®æ—¶æ‰è¯»å–
                    if st.button("ç¡®è®¤åŠ è½½æ•°æ®"):
                         with st.spinner("æ­£åœ¨è¯»å– Excel..."):
                            df_loaded = load_excel(uploaded_file, selected_sheet)
                            if df_loaded is not None:
                                df_loaded = df_loaded.reset_index(drop=True)
                                st.session_state.df = df_loaded
                                st.success(f"å·²åŠ è½½ {len(df_loaded)} æ¡æ•°æ®")
                
            if st.session_state.df is not None:
                st.info(f"å½“å‰å·²åŠ è½½: {len(st.session_state.df)} æ¡")

        with col2:
            api_key = st.text_input(
                "API Key",
                value="sk-xxxx",
                type="password",
            )
            base_url = st.text_input("Base URL", value="https://ark.cn-beijing.volces.com/api/v3")
            model_name = st.text_input("Model Name", value="ep-20250530201032-d9f2d")

    if st.session_state.df is None:
        st.info("è¯·å…ˆä¸Šä¼  Excel æ–‡ä»¶ã€‚")
        return

    df = st.session_state.df

    col_sel1, col_sel2 = st.columns(2)
    with col_sel1:
        text_col = st.selectbox("é€‰æ‹©ä¸»è¦å†…å®¹åˆ—", df.columns)
    with col_sel2:
        context_cols = st.multiselect("é€‰æ‹©è¾…åŠ©ä¿¡æ¯åˆ—", [c for c in df.columns if c != text_col])

    st.subheader("ğŸ¤– Prompt ä¼˜åŒ–åŠ©æ‰‹")
    
    col_prompt, col_chat = st.columns([1, 1])
    
    with col_prompt:
        default_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åˆ†ç±»åŠ©æ‰‹ã€‚è¯·åˆ†æå†…å®¹ï¼Œå¹¶ä¸¥æ ¼è¾“å‡ºä»¥ä¸‹ JSON æ ¼å¼ï¼š
{
    "category": "äº‹ä»¶åˆ†ç±»",
    "sentiment": "æƒ…æ„Ÿå€¾å‘",
    "reason": "åˆ¤æ–­ç†ç”±"
}"""
        system_prompt = st.text_area("System Prompt (å¯ç›´æ¥ä¿®æ”¹)", value=default_prompt, height=300)

    with col_chat:
        st.write("ğŸ’¬ **ä¸ AI å¯¹è¯ä¼˜åŒ– Prompt**")
        if "chat_history" not in st.session_state:
            st.session_state.chat_history = []

        # æ˜¾ç¤ºå†å²å¯¹è¯
        chat_container = st.container(height=200)
        for msg in st.session_state.chat_history:
            chat_container.chat_message(msg["role"]).write(msg["content"])

        if user_input := st.chat_input("è¾“å…¥ä¿®æ”¹æ„è§ï¼ˆä¾‹å¦‚ï¼šå¸®æˆ‘å¢åŠ ä¸€ä¸ª'è´­ä¹°æ„æ„¿'å­—æ®µï¼‰..."):
            # ç”¨æˆ·æ¶ˆæ¯ä¸Šå±
            st.session_state.chat_history.append({"role": "user", "content": user_input})
            chat_container.chat_message("user").write(user_input)

            # è°ƒç”¨ AI ä¼˜åŒ– Prompt
            try:
                client = OpenAI(api_key=api_key, base_url=base_url)
                optimize_prompt = f"""
                ä½ æ˜¯ä¸€ä¸ª Prompt ä¼˜åŒ–ä¸“å®¶ã€‚
                
                ã€å½“å‰ Promptã€‘
                {system_prompt}
                
                ã€ç”¨æˆ·éœ€æ±‚ã€‘
                {user_input}
                
                è¯·æ ¹æ®ç”¨æˆ·éœ€æ±‚ä¿®æ”¹å½“å‰ Promptã€‚åªè¿”å›ä¿®æ”¹åçš„ Prompt å†…å®¹ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæˆ–å…¶ä»–åºŸè¯ã€‚
                ç¡®ä¿ä¿ç•™ JSON è¾“å‡ºæ ¼å¼çš„è¦æ±‚ã€‚
                """
                
                response = client.chat.completions.create(
                    model=model_name,
                    messages=[{"role": "user", "content": optimize_prompt}],
                    temperature=0.7
                )
                
                ai_reply = response.choices[0].message.content
                
                # AI å›å¤ä¸Šå±
                st.session_state.chat_history.append({"role": "assistant", "content": ai_reply})
                chat_container.chat_message("assistant").write(ai_reply)
                
                # æç¤ºç”¨æˆ·æ‰‹åŠ¨å¤åˆ¶
                st.info("ğŸ’¡ AI å·²ç”Ÿæˆæ–° Promptï¼Œè¯·æ‰‹åŠ¨å¤åˆ¶ä¸Šé¢çš„å›å¤å†…å®¹å¹¶ç²˜è´´åˆ°å·¦ä¾§è¾“å…¥æ¡†ä¸­ã€‚")
                
            except Exception as e:
                st.error(f"AI è°ƒç”¨å¤±è´¥: {e}")

    st.header("2. æµ‹è¯•è¿è¡Œ")
    col_test1, col_test2 = st.columns([1, 3])
    with col_test1:
        test_n = st.number_input("è®¾ç½®æµ‹è¯•æ¡æ•°", min_value=1, max_value=1000, value=50, step=10)
    
    with col_test2:
        # æ·»åŠ ä¸€äº›å‚ç›´é—´è·ï¼Œè®©æŒ‰é’®å’Œè¾“å…¥æ¡†å¯¹é½
        st.write("") 
        st.write("")
        if st.button(f"ğŸ§ª æµ‹è¯• {test_n} æ¡"):
            sample_n = min(test_n, len(df))
            sample_df = df.sample(n=sample_n, random_state=42)
            st.session_state.sample_indices = sample_df.index.tolist()

            st.info("æ­£åœ¨æµ‹è¯•...")
            progress_bar = st.progress(0.0)

            # æ”¹ä¸ºå¹¶å‘æ‰§è¡Œæµ‹è¯•
            with concurrent.futures.ThreadPoolExecutor(max_workers=50) as executor:
                future_to_idx = {
                    executor.submit(call_llm, row, text_col, context_cols, system_prompt, api_key, base_url, model_name): idx 
                    for idx, row in sample_df.iterrows()
                }
                
                completed = 0
                total = len(sample_df)
                
                for future in concurrent.futures.as_completed(future_to_idx):
                    idx = future_to_idx[future]
                    try:
                        res = future.result()
                        parsed = parse_json_result(res)
                        st.session_state.processed_data[idx] = parsed
                    except Exception as e:
                        st.session_state.processed_data[idx] = {"error": str(e)}
                    
                    completed += 1
                    progress_bar.progress(completed / total)

            st.success("æµ‹è¯•å®Œæˆï¼")

    if st.session_state.sample_indices:
        st.subheader("ğŸ“ æ ¡å¯¹ç»“æœ")
        st.caption("è¯·åœ¨ä¸‹æ–¹è¡¨æ ¼ä¸­ç›´æ¥ä¿®æ”¹æ•°æ®ã€‚å¦‚æœ AI ç»“æœæœ‰è¯¯ï¼Œè¯·å‹¾é€‰ã€âŒ æ ‡è®°é”™è¯¯ã€åˆ—ã€‚")

        sample_rows = []
        for idx in st.session_state.sample_indices:
            base_row = df.loc[idx].to_dict()
            ai_res = st.session_state.processed_data.get(idx, {})
            for k, v in ai_res.items():
                base_row[f"AI_{k}"] = v
            
            # æ·»åŠ æ ‡è®°é”™è¯¯åˆ—
            base_row["âŒ æ ‡è®°é”™è¯¯"] = st.session_state.error_flags.get(idx, False)
            base_row["_original_index"] = idx
            sample_rows.append(base_row)

        # é…ç½®åˆ—æ˜¾ç¤ºï¼Œè®© Checkbox æ›´ç›´è§‚
        column_config = {
            "âŒ æ ‡è®°é”™è¯¯": st.column_config.CheckboxColumn(
                "æ ‡è®°é”™è¯¯",
                help="å¦‚æœ AI ç»“æœä¸å¯¹ï¼Œè¯·å‹¾é€‰æ­¤é¡¹",
                default=False,
            )
        }

        sample_edit_df = st.data_editor(
            pd.DataFrame(sample_rows), 
            num_rows="dynamic",
            column_config=column_config
        )
        
        if not sample_edit_df.empty:
            error_count = 0
            for _, r in sample_edit_df.iterrows():
                idx = int(r["_original_index"])
                
                # æ›´æ–° AI ç»“æœæ•°æ®
                updated_res = {k.replace("AI_", ""): v for k, v in r.items() if isinstance(k, str) and k.startswith("AI_")}
                st.session_state.processed_data[idx] = updated_res

                # æ›´æ–°é”™è¯¯æ ‡è®°çŠ¶æ€
                is_err = r.get("âŒ æ ‡è®°é”™è¯¯", False)
                st.session_state.error_flags[idx] = is_err
                if is_err:
                    error_count += 1
            
            # å®æ—¶æ˜¾ç¤ºé”™è¯¯ç‡æŒ‡æ ‡
            if len(sample_rows) > 0:
                error_rate = error_count / len(sample_rows)
                st.metric("ğŸš© å½“å‰é”™è¯¯ç‡", f"{error_rate:.1%}", f"å·²æ ‡è®° {error_count} æ¡é”™è¯¯")

    st.header("3. å…¨é‡è¿è¡Œ")
    if st.button("ğŸš€ è¿è¡Œå‰©ä½™æ‰€æœ‰æ•°æ®"):
        all_indices = df.index.tolist()
        remaining_indices = [i for i in all_indices if i not in st.session_state.processed_data]
        
        if not remaining_indices:
            st.warning("æ‰€æœ‰æ•°æ®å·²å¤„ç†ã€‚")
        else:
            st.info(f"æ­£åœ¨å¹¶å‘å¤„ç† {len(remaining_indices)} æ¡æ•°æ®...")
            progress_bar = st.progress(0.0)
            status_text_run = st.empty()
            
            completed = 0
            total = len(remaining_indices)
            
            # å¢åŠ å¹¶å‘æ•°åˆ° 50
            with concurrent.futures.ThreadPoolExecutor(max_workers=50) as executor:
                future_to_idx = {
                    executor.submit(call_llm, df.loc[idx], text_col, context_cols, system_prompt, api_key, base_url, model_name): idx 
                    for idx in remaining_indices
                }
                
                for future in concurrent.futures.as_completed(future_to_idx):
                    idx = future_to_idx[future]
                    try:
                        res = future.result()
                        parsed = parse_json_result(res)
                        st.session_state.processed_data[idx] = parsed
                    except Exception as e:
                        st.session_state.processed_data[idx] = {"error": str(e)}
                    
                    completed += 1
                    progress_bar.progress(completed / total)
                    status_text_run.text(f"è¿›åº¦ï¼š{completed}/{total}")
            
            st.success("å…¨é‡è¿è¡Œå®Œæˆï¼")

    if st.session_state.processed_data:
        st.header("4. å¯¼å‡ºä¸è´¨æ£€")
        
        merged_rows = []
        for idx in df.index:
            base_row = df.loc[idx].to_dict()
            ai_res = st.session_state.processed_data.get(idx, {})
            for k, v in ai_res.items():
                base_row[f"AI_{k}"] = v
            merged_rows.append(base_row)
        
        final_df = pd.DataFrame(merged_rows)
        
        col_a, col_b = st.columns(2)
        with col_a:
            buffer = io.BytesIO()
            with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
                final_df.to_excel(writer, index=False)
            st.download_button("ğŸ“¥ ä¸‹è½½å…¨é‡ç»“æœ", buffer.getvalue(), "æ‰“æ ‡ç»“æœ_å…¨é‡.xlsx")
            
        with col_b:
            ai_cols = [c for c in final_df.columns if c.startswith("AI_")]
            if ai_cols:
                qa_col = st.selectbox("é€‰æ‹©æŠ½æ ·åˆ—", ai_cols)
                if st.button("ç”ŸæˆæŠ½æ ·è¡¨"):
                    qa_df = stratified_sample(final_df, qa_col, frac=0.1)
                    buffer_qa = io.BytesIO()
                    with pd.ExcelWriter(buffer_qa, engine="openpyxl") as writer:
                        qa_df.to_excel(writer, index=False)
                    st.download_button("ğŸ“¥ ä¸‹è½½è´¨æ£€æŠ½æ ·è¡¨", buffer_qa.getvalue(), f"è´¨æ£€_{qa_col}.xlsx")

if __name__ == "__main__":
    main_app()
